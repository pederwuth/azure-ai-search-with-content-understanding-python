{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video Search Webapp with Azure Content Understanding\n",
    "## Objective\n",
    "This document will guide you through how to run and use the Video Search Webapp sample as well as providing the backend server.\n",
    "1. Set up Azure resources and acquire the necessary endpoints, API keys, API versions, and deployment names.\n",
    "2. Build and run node.js server that serves the frontend webapp.\n",
    "3. Launch and port forward the backend server through this Python Notebook.\n",
    "\n",
    "\n",
    "## Pre-requisites\n",
    "### Follow the overall Azure role setup for your resources\n",
    "1. [Setup Readme](https://github.com/Azure-Samples/azure-ai-search-with-content-understanding-python/blob/main/README.md)\n",
    "2. Install az login using `curl -sL https://aka.ms/InstallAzureCLIDeb | sudo bash`\n",
    "3. Run `az login --use-device-code` or `azd auth login`\n",
    "### Environment Variable Setup for Azure OpenAI\n",
    "Populate your .env file with these endpoints and other info.\n",
    "1. Azure OpenAI Resource's Endpoint\n",
    "   - **Where to find it**: In the Azure Portal, go to your **Azure OpenAI resource** > **Keys and Endpoint** tab.\n",
    "   - **Example**: \"https://<your-resource-name>.openai.azure.com/\"\n",
    "\n",
    "2. Completions Deployment Name\n",
    "   - **Where to find it**: Click on **Explore Azure AI Studio** on the Overview page of the Azure OpenAI resource, Under **Deployments**, find the deployment name for the Completions model.\n",
    "   - **Example**: \"gpt4o\"\n",
    "\n",
    "3. Completions API Version\n",
    "   - **Where to find it**: At the end of the Target URI in the **Deployments** page in **Azure AI Studio**.\n",
    "   - **Example**: \"2024-08-01-preview\"\n",
    "\n",
    "4. Embeddings Deployment Name\n",
    "   - **Where to find it**: Similar to the Completions deployment, find this under **Deployments**.\n",
    "   - **Example**: \"text-embedding-ada-002\"\n",
    "\n",
    "5. Embeddings API Version\n",
    "   - **Where to find it**: At the end of the Target URI in the **Deployments** page in **Azure AI Studio**.\n",
    "   - **Example**: \"2023-05-15\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Webapp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "\n",
    "# Get the current working directory of the notebook\n",
    "notebook_path = Path().resolve()\n",
    "\n",
    "# Print the notebook's working directory\n",
    "print(\"Notebook working directory:\", notebook_path)\n",
    "\n",
    "# Change the current working directory to the notebook's directory\n",
    "# This is necessary to ensure that the script runs in the correct context\n",
    "# and can access the required files and folders.\n",
    "# Note: This is a workaround for Jupyter Notebook's behavior of not\n",
    "# automatically setting the working directory to the notebook's location.\n",
    "# This is especially important when running the script in a Jupyter Notebook\n",
    "# environment where the working directory may not be set to the notebook's location.\n",
    "os.chdir(notebook_path)\n",
    "\n",
    "# Change the current working directory to the Node.js project folder\n",
    "os.chdir(\"../nodejs/video-search-app\")\n",
    "\n",
    "# Verify the current working directory\n",
    "print(\"Current working directory:\", os.getcwd())\n",
    "\n",
    "# Update and install Node.js, npm\n",
    "os.system(\"sudo apt update\")\n",
    "os.system(\"sudo apt install -y nodejs npm\")\n",
    "\n",
    "# Install dependencies\n",
    "os.system(\"npm install --legacy-peer-deps\")\n",
    "\n",
    "# Build the project\n",
    "os.system(\"npm run build\")\n",
    "\n",
    "# Start the Next.js server using subprocess\n",
    "# This runs in the background and won't block the notebook\n",
    "with open(\"server.log\", \"w\") as log_file:\n",
    "    process = subprocess.Popen(\n",
    "        [\"npm\", \"run\", \"start\"],\n",
    "        stdout=log_file,\n",
    "        stderr=subprocess.STDOUT\n",
    "    )\n",
    "\n",
    "print(f\"Started Next.js server (PID: {process.pid}). Logs are in server.log.\")\n",
    "\n",
    "# Change the current working directory back to the notebooks folder\n",
    "os.chdir(\"../../notebooks/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running this code, navigate to the Ports tab next to Terminal, you should see the webapp being hosted at port 3000, the \"Forwarded Address\" is where you can find the webapp.\n",
    "![alt text](images/find-webapp-url.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt for conversational video search. Feel free to modify the prompt as needed.\n",
    "prompt_str = \"\"\"You are an assistant for finding relevant video segments given a question. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise. If you find a relevant video segment, summarize the details of the segment. Include the startTimeMs and endTimeMs. At the end of your response, output the sas url of the segment verbatim, followed by a space, and followed by the starting time of the segment in integer seconds, don't add parenthesis or any other character before or after the starting time or the url. Make sure the output is URL followed by the starting time, in that order.\n",
    "Question: {question} \n",
    "Context: {context} \n",
    "Answer:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify, send_from_directory\n",
    "from flask_cors import CORS\n",
    "from langchain.schema import Document\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "from langchain.schema import StrOutputParser\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain_community.vectorstores import AzureSearch\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "import os\n",
    "import sys\n",
    "import uuid\n",
    "import threading\n",
    "import time\n",
    "from pathlib import Path\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Load and validate Azure AI Services configs\n",
    "AZURE_AI_SERVICE_ENDPOINT = os.getenv(\"AZURE_AI_SERVICE_ENDPOINT\")\n",
    "AZURE_AI_SERVICE_API_VERSION = os.getenv(\"AZURE_AI_SERVICE_API_VERSION\", \"2024-12-01-preview\")\n",
    "\n",
    "# Load and validate Azure OpenAI configs\n",
    "AZURE_OPENAI_ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "AZURE_OPENAI_CHAT_DEPLOYMENT_NAME = os.getenv(\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\")\n",
    "AZURE_OPENAI_CHAT_API_VERSION = os.getenv(\"AZURE_OPENAI_CHAT_API_VERSION\", \"2024-08-01-preview\")\n",
    "AZURE_OPENAI_EMBEDDING_DEPLOYMENT_NAME = os.getenv(\"AZURE_OPENAI_EMBEDDING_DEPLOYMENT_NAME\")\n",
    "AZURE_OPENAI_EMBEDDING_API_VERSION = os.getenv(\"AZURE_OPENAI_EMBEDDING_API_VERSION\", \"2023-05-15\")\n",
    "\n",
    "# Load and validate Azure Search Services configs\n",
    "AZURE_SEARCH_ENDPOINT = os.getenv(\"AZURE_SEARCH_ENDPOINT\")\n",
    "INDEX_NAME = os.getenv(\"AZURE_SEARCH_INDEX_NAME\", \"sample-index-video\")\n",
    "\n",
    "from azure.identity import DefaultAzureCredential, get_bearer_token_provider\n",
    "credential = DefaultAzureCredential()\n",
    "token_provider = get_bearer_token_provider(credential, \"https://cognitiveservices.azure.com/.default\")\n",
    "\n",
    "parent_dir = Path(Path.cwd()).parent\n",
    "sys.path.append(\n",
    "    str(parent_dir)\n",
    ")\n",
    "\n",
    "from python.content_understanding_client import AzureContentUnderstandingClient\n",
    "\n",
    "app = Flask(__name__)\n",
    "CORS(app)\n",
    "\n",
    "# Job tracking system\n",
    "# Dictionary to store job information\n",
    "jobs = {}\n",
    "\n",
    "# Job status constants\n",
    "JOB_STATUS_PENDING = \"pending\"\n",
    "JOB_STATUS_PROCESSING = \"processing\"\n",
    "JOB_STATUS_INDEXING = \"indexing\"\n",
    "JOB_STATUS_COMPLETED = \"completed\"\n",
    "JOB_STATUS_FAILED = \"failed\"\n",
    "JOB_STATUS_CANCELLED = \"cancelled\"\n",
    "\n",
    "# Utility functions for JSON processing\n",
    "def convert_values_to_strings(json_obj):\n",
    "    return [str(value) for value in json_obj]\n",
    "\n",
    "def remove_markdown(json_obj):\n",
    "    for segment in json_obj:\n",
    "        if 'markdown' in segment:\n",
    "            del segment['markdown']\n",
    "    return json_obj\n",
    "\n",
    "def process_cu_scene_description(scene_description, video_url):\n",
    "    audio_visual_segments = scene_description[\"result\"][\"contents\"]\n",
    "    for segment in audio_visual_segments:\n",
    "        segment[\"url\"] = video_url\n",
    "    audio_visual_splits = [json.dumps(v) for v in audio_visual_segments]\n",
    "    docs = [Document(page_content=v) for v in audio_visual_splits]\n",
    "    return docs\n",
    "\n",
    "def embed_and_index_chunks(docs):\n",
    "    aoai_embeddings = AzureOpenAIEmbeddings(\n",
    "        azure_deployment=AZURE_OPENAI_EMBEDDING_DEPLOYMENT_NAME,\n",
    "        openai_api_version=AZURE_OPENAI_EMBEDDING_API_VERSION,  # e.g., \"2023-12-01-preview\"\n",
    "        azure_endpoint=AZURE_OPENAI_ENDPOINT,\n",
    "        azure_ad_token_provider=token_provider\n",
    "    )\n",
    "\n",
    "    vector_store: AzureSearch = AzureSearch(\n",
    "        azure_search_endpoint=AZURE_SEARCH_ENDPOINT,\n",
    "        azure_search_key=None,\n",
    "        index_name=INDEX_NAME,\n",
    "        embedding_function=aoai_embeddings.embed_query,\n",
    "    )\n",
    "    vector_store.add_documents(documents=docs)\n",
    "\n",
    "# RAG\n",
    "def setup_rag_chain(vector_store):\n",
    "    retriever = vector_store.as_retriever(search_type=\"similarity\", k=3)\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_template(prompt_str)\n",
    "    llm = AzureChatOpenAI(\n",
    "        openai_api_version=AZURE_OPENAI_CHAT_API_VERSION,  # e.g., \"2023-12-01-preview\"\n",
    "        azure_deployment=AZURE_OPENAI_CHAT_DEPLOYMENT_NAME,\n",
    "        azure_ad_token_provider=token_provider,\n",
    "        temperature=0.7,\n",
    "    )\n",
    "\n",
    "    def format_docs(docs):\n",
    "        return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "    rag_chain = (\n",
    "        {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "        | prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "    return rag_chain\n",
    "\n",
    "def conversational_search(query):\n",
    "    aoai_embeddings = AzureOpenAIEmbeddings(\n",
    "        azure_deployment=AZURE_OPENAI_EMBEDDING_DEPLOYMENT_NAME,\n",
    "        openai_api_version=AZURE_OPENAI_EMBEDDING_API_VERSION,  # e.g., \"2023-12-01-preview\"\n",
    "        azure_endpoint=AZURE_OPENAI_ENDPOINT,\n",
    "        azure_ad_token_provider=token_provider\n",
    "    )\n",
    "\n",
    "    vector_store: AzureSearch = AzureSearch(\n",
    "        azure_search_endpoint=AZURE_SEARCH_ENDPOINT,\n",
    "        azure_search_key=None,\n",
    "        index_name=INDEX_NAME,\n",
    "        embedding_function=aoai_embeddings.embed_query,\n",
    "    )\n",
    "\n",
    "    rag_chain = setup_rag_chain(vector_store)\n",
    "    output = rag_chain.invoke(query)\n",
    "    print(output)\n",
    "    return output\n",
    "\n",
    "def similarity_search(query):\n",
    "    aoai_embeddings = AzureOpenAIEmbeddings(\n",
    "        azure_deployment=AZURE_OPENAI_EMBEDDING_DEPLOYMENT_NAME,\n",
    "        openai_api_version=AZURE_OPENAI_EMBEDDING_API_VERSION,  # e.g., \"2023-12-01-preview\"\n",
    "        azure_endpoint=AZURE_OPENAI_ENDPOINT,\n",
    "        azure_ad_token_provider=token_provider\n",
    "    )\n",
    "\n",
    "    vector_store: AzureSearch = AzureSearch(\n",
    "        azure_search_endpoint=AZURE_SEARCH_ENDPOINT,\n",
    "        azure_search_key=None,\n",
    "        index_name=INDEX_NAME,\n",
    "        embedding_function=aoai_embeddings.embed_query,\n",
    "    )\n",
    "\n",
    "    docs = vector_store.similarity_search(\n",
    "        query=query,\n",
    "        k=3,\n",
    "        search_type=\"similarity\",\n",
    "    )\n",
    "    return docs\n",
    "\n",
    "def hybrid_search(query):\n",
    "    aoai_embeddings = AzureOpenAIEmbeddings(\n",
    "        azure_deployment=AZURE_OPENAI_EMBEDDING_DEPLOYMENT_NAME,\n",
    "        openai_api_version=AZURE_OPENAI_EMBEDDING_API_VERSION,  # e.g., \"2023-12-01-preview\"\n",
    "        azure_endpoint=AZURE_OPENAI_ENDPOINT,\n",
    "        azure_ad_token_provider=token_provider\n",
    "    )\n",
    "\n",
    "    vector_store: AzureSearch = AzureSearch(\n",
    "        azure_search_endpoint=AZURE_SEARCH_ENDPOINT,\n",
    "        azure_search_key=None,\n",
    "        index_name=INDEX_NAME,\n",
    "        embedding_function=aoai_embeddings.embed_query,\n",
    "    )\n",
    "\n",
    "    # Use hybrid search which combines semantic and keyword search\n",
    "    docs = vector_store.hybrid_search(query=query, k=5)\n",
    "    return docs\n",
    "\n",
    "# Process video with Azure Content Understanding\n",
    "def process_video_with_cu(video_url, analyzer_schema):\n",
    "    try:\n",
    "        # Initialize the Azure Content Understanding client\n",
    "        import uuid\n",
    "        \n",
    "        # Process the video URL with the analyzer\n",
    "        analyzer_id = analyzer_schema.get(\"analyzerId\") + \"_\" + str(uuid.uuid4())\n",
    "        print(f\"Processing video URL: {video_url} with analyzer ID: {analyzer_id}\")\n",
    "        \n",
    "        cu_client = AzureContentUnderstandingClient(\n",
    "            endpoint=AZURE_AI_SERVICE_ENDPOINT,\n",
    "            api_version=AZURE_AI_SERVICE_API_VERSION,\n",
    "            token_provider=token_provider,\n",
    "            x_ms_useragent=\"azure-ai-content-understanding-python/search_with_video_webapp\", # This header is used for sample usage telemetry, please comment out this line if you want to opt out.\n",
    "        )\n",
    "        print(\"Azure Content Understanding client initialized\")\n",
    "        response = cu_client.begin_create_analyzer(analyzer_id, analyzer_template=analyzer_schema)\n",
    "        result = cu_client.poll_result(response)\n",
    "        print(f\"Analyzer created with ID: {analyzer_id}\")\n",
    "\n",
    "        response = cu_client.begin_analyze(analyzer_id, file_location=video_url)\n",
    "        print(f\"Video analysis started with ID: {analyzer_id}\")\n",
    "        video_cu_result = cu_client.poll_result(response, timeout_seconds=36000)\n",
    "        print(f\"Video analysis completed with ID: {analyzer_id}\")\n",
    "\n",
    "        cu_client.delete_analyzer(analyzer_id)\n",
    "        \n",
    "        # For now, just return success\n",
    "        return True, \"Video URL processed successfully\", video_cu_result\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing video with Azure Content Understanding: {str(e)}\")\n",
    "        return False, f\"Failed to process video: {str(e)}\", None\n",
    "\n",
    "# Background job processing function\n",
    "def process_video_job(job_id, video_url, analyzer_schema):\n",
    "    try:\n",
    "        # Update job status to processing\n",
    "        jobs[job_id][\"status\"] = JOB_STATUS_PROCESSING\n",
    "        jobs[job_id][\"progress\"] = 30\n",
    "        jobs[job_id][\"message\"] = \"Processing video...\"\n",
    "        \n",
    "        # Process the video\n",
    "        success, message, video_cu_result = process_video_with_cu(video_url, analyzer_schema)\n",
    "        \n",
    "        if not success:\n",
    "            jobs[job_id][\"status\"] = JOB_STATUS_FAILED\n",
    "            jobs[job_id][\"error\"] = message\n",
    "            jobs[job_id][\"progress\"] = 0\n",
    "            return\n",
    "        \n",
    "        # Update job status to indexing\n",
    "        jobs[job_id][\"status\"] = JOB_STATUS_INDEXING\n",
    "        jobs[job_id][\"progress\"] = 80\n",
    "        jobs[job_id][\"message\"] = \"Indexing content...\"\n",
    "        \n",
    "        # Process and index the results\n",
    "        try:\n",
    "            docs = process_cu_scene_description(video_cu_result, video_url)\n",
    "            embed_and_index_chunks(docs)\n",
    "            print(\"Successfully indexed video content\")\n",
    "            \n",
    "            # Update job status to completed\n",
    "            jobs[job_id][\"status\"] = JOB_STATUS_COMPLETED\n",
    "            jobs[job_id][\"progress\"] = 100\n",
    "            jobs[job_id][\"message\"] = \"Processing completed!\"\n",
    "            jobs[job_id][\"result\"] = {\n",
    "                \"message\": \"Video indexed with custom analyzer successfully\", \n",
    "                \"data\": analyzer_schema,\n",
    "                \"videoUrl\": video_url\n",
    "            }\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing scene description: {str(e)}\")\n",
    "            jobs[job_id][\"status\"] = JOB_STATUS_FAILED\n",
    "            jobs[job_id][\"error\"] = f\"Failed to index content: {str(e)}\"\n",
    "            jobs[job_id][\"progress\"] = 0\n",
    "    except Exception as e:\n",
    "        print(f\"Error in job processing: {str(e)}\")\n",
    "        jobs[job_id][\"status\"] = JOB_STATUS_FAILED\n",
    "        jobs[job_id][\"error\"] = f\"Job processing error: {str(e)}\"\n",
    "        jobs[job_id][\"progress\"] = 0\n",
    "    \n",
    "    # Check if job was cancelled\n",
    "    if jobs[job_id][\"status\"] == JOB_STATUS_CANCELLED:\n",
    "        print(f\"Job {job_id} was cancelled\")\n",
    "\n",
    "# New endpoint for configuration settings\n",
    "@app.route('/config', methods=['POST'])\n",
    "def update_config():\n",
    "    try:\n",
    "        # No need to process any Azure configuration from the frontend\n",
    "        # Just return success as the configuration is now read from .env file\n",
    "        print(\"Configuration endpoint called - settings are now read from .env file\")\n",
    "        \n",
    "        return jsonify({'message': 'Configuration settings are now read from environment variables'}), 200\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error in config endpoint: {str(e)}\")\n",
    "        return jsonify({'error': f'Server error: {str(e)}'}), 500\n",
    "\n",
    "# Updated search endpoint to support both similarity and hybrid search\n",
    "@app.route('/search', methods=['POST'])\n",
    "def search():\n",
    "    data = request.get_json()\n",
    "    query = data.get('query', '')\n",
    "    search_type = data.get('searchType', 'similarity')  # Default to similarity if not specified\n",
    "    \n",
    "    print(f\"Search query: {query}, Search type: {search_type}\")\n",
    "    \n",
    "    if not query:\n",
    "        return jsonify({'error': 'No query provided'}), 400\n",
    "    \n",
    "    try:\n",
    "        # Perform search based on the selected search type\n",
    "        response = []\n",
    "        \n",
    "        if search_type == 'hybrid':\n",
    "            results = hybrid_search(query)\n",
    "        else:  # Default to similarity search\n",
    "            results = similarity_search(query)\n",
    "            \n",
    "        if results:\n",
    "            for res in results:\n",
    "                page_content = json.loads(res.page_content)\n",
    "                res_obj = {\n",
    "                    \"startTimeMs\": page_content[\"startTimeMs\"],\n",
    "                    \"endTimeMs\": page_content[\"endTimeMs\"],\n",
    "                    \"fields\": page_content[\"fields\"],\n",
    "                    \"videoUrl\": page_content.get(\"url\", \"\")  # Include the video URL in the response\n",
    "                }\n",
    "                response.append(res_obj)\n",
    "        print(f\"Found {len(response)} results\")\n",
    "        \n",
    "        return jsonify({\n",
    "            'results': response,\n",
    "            'searchType': search_type\n",
    "        }), 200\n",
    "    except Exception as e:\n",
    "        print(f\"Search error: {str(e)}\")\n",
    "        return jsonify({'error': f'Search failed: {str(e)}'}), 500\n",
    "\n",
    "conversations = []\n",
    "# Endpoint for chat\n",
    "@app.route('/chat', methods=['POST'])\n",
    "def chat():\n",
    "    data = request.get_json()\n",
    "    user_message = data.get('message', '')\n",
    "\n",
    "    reply = conversational_search(user_message)\n",
    "    ai_reply = f\"{reply}\"  # Replace with real AI integration.\n",
    "\n",
    "    # Save this message pair in memory.\n",
    "    conversations.append({\n",
    "        'user': user_message,\n",
    "        'ai': ai_reply\n",
    "    })\n",
    "\n",
    "    return jsonify({\n",
    "        'reply': ai_reply\n",
    "    })\n",
    "\n",
    "# New endpoint to start a video processing job\n",
    "@app.route('/upload/start', methods=['POST'])\n",
    "def start_upload_job():\n",
    "    if 'jsonFile' not in request.files:\n",
    "        return jsonify({'error': 'No JSON file provided'}), 400\n",
    "    \n",
    "    file = request.files['jsonFile']\n",
    "    video_url = str(request.form.get('videoUrl', ''))\n",
    "    \n",
    "    if file.filename == '':\n",
    "        return jsonify({'error': 'No selected file'}), 400\n",
    "    \n",
    "    if not video_url:\n",
    "        return jsonify({'error': 'No video URL provided'}), 400\n",
    "    \n",
    "    # Check if settings are configured\n",
    "    if not all([\n",
    "        AZURE_OPENAI_EMBEDDING_DEPLOYMENT_NAME,\n",
    "        AZURE_OPENAI_EMBEDDING_API_VERSION,\n",
    "        AZURE_OPENAI_ENDPOINT,\n",
    "        AZURE_OPENAI_CHAT_DEPLOYMENT_NAME,\n",
    "        AZURE_OPENAI_CHAT_API_VERSION,\n",
    "        AZURE_SEARCH_ENDPOINT,\n",
    "        INDEX_NAME,\n",
    "        AZURE_AI_SERVICE_ENDPOINT,\n",
    "        AZURE_AI_SERVICE_API_VERSION,\n",
    "    ]):\n",
    "        return jsonify({'error': 'Configuration settings must be set before uploading files'}), 400\n",
    "    \n",
    "    try:\n",
    "        # Process JSON file\n",
    "        json_data = json.load(file)\n",
    "        print(json.dumps(json_data, indent=2))  # Print the received JSON object\n",
    "        \n",
    "        # Validate the JSON structure\n",
    "        required_fields = [\"analyzerId\", \"name\", \"description\", \"scenario\", \"config\", \"fieldSchema\"]\n",
    "        missing_fields = [field for field in required_fields if field not in json_data]\n",
    "        \n",
    "        if missing_fields:\n",
    "            return jsonify({\n",
    "                'error': f'Invalid JSON format. Missing required fields: {\", \".join(missing_fields)}'\n",
    "            }), 400\n",
    "        \n",
    "        # Create a new job ID\n",
    "        job_id = str(uuid.uuid4())\n",
    "        \n",
    "        # Store job information\n",
    "        jobs[job_id] = {\n",
    "            \"status\": JOB_STATUS_PENDING,\n",
    "            \"progress\": 10,\n",
    "            \"message\": \"Job created, waiting to start...\",\n",
    "            \"videoUrl\": video_url,\n",
    "            \"analyzer_schema\": json_data,\n",
    "            \"created_at\": time.time(),\n",
    "            \"updated_at\": time.time()\n",
    "        }\n",
    "        \n",
    "        # Start a background thread to process the job\n",
    "        thread = threading.Thread(\n",
    "            target=process_video_job,\n",
    "            args=(job_id, video_url, json_data)\n",
    "        )\n",
    "        thread.daemon = True\n",
    "        thread.start()\n",
    "        \n",
    "        return jsonify({\n",
    "            \"jobId\": job_id,\n",
    "            \"message\": \"Video processing job started\",\n",
    "            \"status\": JOB_STATUS_PENDING\n",
    "        }), 202\n",
    "        \n",
    "    except json.JSONDecodeError:\n",
    "        return jsonify({'error': 'Invalid JSON format'}), 400\n",
    "    except Exception as e:\n",
    "        print(f\"Error starting upload job: {str(e)}\")\n",
    "        return jsonify({'error': f'Failed to start upload job: {str(e)}'}), 500\n",
    "\n",
    "# Endpoint to check job status\n",
    "@app.route('/upload/status/<job_id>', methods=['GET'])\n",
    "def check_job_status(job_id):\n",
    "    if job_id not in jobs:\n",
    "        return jsonify({\n",
    "            \"error\": \"Job not found\"\n",
    "        }), 404\n",
    "    \n",
    "    job = jobs[job_id]\n",
    "    \n",
    "    # Update the last accessed time\n",
    "    job[\"updated_at\"] = time.time()\n",
    "    \n",
    "    response = {\n",
    "        \"status\": job[\"status\"],\n",
    "        \"progress\": job[\"progress\"],\n",
    "        \"message\": job.get(\"message\", \"\")\n",
    "    }\n",
    "    \n",
    "    # Add result if job is completed\n",
    "    if job[\"status\"] == JOB_STATUS_COMPLETED and \"result\" in job:\n",
    "        response[\"result\"] = job[\"result\"]\n",
    "    \n",
    "    # Add error if job failed\n",
    "    if job[\"status\"] == JOB_STATUS_FAILED and \"error\" in job:\n",
    "        response[\"error\"] = job[\"error\"]\n",
    "    \n",
    "    return jsonify(response), 200\n",
    "\n",
    "# Endpoint to cancel a job\n",
    "@app.route('/upload/cancel/<job_id>', methods=['POST'])\n",
    "def cancel_job(job_id):\n",
    "    if job_id not in jobs:\n",
    "        return jsonify({\n",
    "            \"error\": \"Job not found\"\n",
    "        }), 404\n",
    "    \n",
    "    job = jobs[job_id]\n",
    "    \n",
    "    # Only allow cancellation of pending or processing jobs\n",
    "    if job[\"status\"] not in [JOB_STATUS_PENDING, JOB_STATUS_PROCESSING, JOB_STATUS_INDEXING]:\n",
    "        return jsonify({\n",
    "            \"error\": f\"Cannot cancel job with status: {job['status']}\"\n",
    "        }), 400\n",
    "    \n",
    "    # Mark the job as cancelled\n",
    "    job[\"status\"] = JOB_STATUS_CANCELLED\n",
    "    job[\"message\"] = \"Job cancelled by user\"\n",
    "    job[\"updated_at\"] = time.time()\n",
    "    \n",
    "    return jsonify({\n",
    "        \"message\": \"Job cancelled successfully\",\n",
    "        \"jobId\": job_id\n",
    "    }), 200\n",
    "\n",
    "# Maintain the original upload endpoint for backward compatibility\n",
    "@app.route('/upload', methods=['POST'])\n",
    "def upload_json():\n",
    "    if 'jsonFile' not in request.files:\n",
    "        return jsonify({'error': 'No JSON file provided'}), 400\n",
    "    \n",
    "    file = request.files['jsonFile']\n",
    "    video_url = str(request.form.get('videoUrl', ''))\n",
    "    \n",
    "    if file.filename == '':\n",
    "        return jsonify({'error': 'No selected file'}), 400\n",
    "    \n",
    "    if not video_url:\n",
    "        return jsonify({'error': 'No video URL provided'}), 400\n",
    "    \n",
    "    # Check if settings are configured\n",
    "    if not all([\n",
    "        AZURE_OPENAI_EMBEDDING_DEPLOYMENT_NAME,\n",
    "        AZURE_OPENAI_EMBEDDING_API_VERSION,\n",
    "        AZURE_OPENAI_ENDPOINT,\n",
    "        AZURE_OPENAI_CHAT_DEPLOYMENT_NAME,\n",
    "        AZURE_OPENAI_CHAT_API_VERSION,\n",
    "        AZURE_SEARCH_ENDPOINT,\n",
    "        INDEX_NAME,\n",
    "        AZURE_AI_SERVICE_ENDPOINT,\n",
    "        AZURE_AI_SERVICE_API_VERSION,\n",
    "    ]):\n",
    "        return jsonify({'error': 'Configuration settings must be set before uploading files'}), 400\n",
    "    \n",
    "    try:\n",
    "        # Process JSON file\n",
    "        json_data = json.load(file)\n",
    "        print(json.dumps(json_data, indent=2))  # Print the received JSON object\n",
    "        \n",
    "        # Validate the JSON structure\n",
    "        required_fields = [\"analyzerId\", \"name\", \"description\", \"scenario\", \"config\", \"fieldSchema\"]\n",
    "        missing_fields = [field for field in required_fields if field not in json_data]\n",
    "        \n",
    "        if missing_fields:\n",
    "            return jsonify({\n",
    "                'error': f'Invalid JSON format. Missing required fields: {\", \".join(missing_fields)}'\n",
    "            }), 400\n",
    "        \n",
    "        # Process the video with Azure Content Understanding\n",
    "        success, message, video_cu_result = process_video_with_cu(video_url, json_data)\n",
    "        \n",
    "        if not success:\n",
    "            return jsonify({'error': message}), 500\n",
    "        \n",
    "        # Process the JSON data if needed\n",
    "        # If this is a scene description, process it and index it\n",
    "        try:\n",
    "            docs = process_cu_scene_description(video_cu_result, video_url)\n",
    "            embed_and_index_chunks(docs)\n",
    "            print(\"Successfully indexed video content\")\n",
    "            return jsonify({\n",
    "                \"message\": \"Video indexed with custom analyzer successfully\", \n",
    "                \"data\": json_data,\n",
    "                \"videoUrl\": video_url\n",
    "            }), 200\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing scene description: {str(e)}\")\n",
    "            # If it's not a scene description or there's an error, just return the JSON\n",
    "            return jsonify({\n",
    "                \"message\": \"JSON configuration and video URL received\", \n",
    "                \"data\": json_data,\n",
    "                \"videoUrl\": video_url\n",
    "            }), 200\n",
    "    except json.JSONDecodeError:\n",
    "        return jsonify({'error': 'Invalid JSON format'}), 400\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing upload: {str(e)}\")\n",
    "        return jsonify({'error': f'Failed to process upload: {str(e)}'}), 500\n",
    "\n",
    "# Job cleanup task\n",
    "def cleanup_old_jobs():\n",
    "    \"\"\"Remove completed, failed, or cancelled jobs older than 24 hours\"\"\"\n",
    "    current_time = time.time()\n",
    "    jobs_to_remove = []\n",
    "    \n",
    "    for job_id, job in jobs.items():\n",
    "        # Keep jobs for 24 hours (86400 seconds)\n",
    "        if job[\"status\"] in [JOB_STATUS_COMPLETED, JOB_STATUS_FAILED, JOB_STATUS_CANCELLED]:\n",
    "            if current_time - job.get(\"updated_at\", 0) > 86400:\n",
    "                jobs_to_remove.append(job_id)\n",
    "    \n",
    "    for job_id in jobs_to_remove:\n",
    "        del jobs[job_id]\n",
    "    \n",
    "    print(f\"Cleaned up {len(jobs_to_remove)} old jobs\")\n",
    "\n",
    "# Start a background thread for job cleanup\n",
    "def start_cleanup_thread():\n",
    "    while True:\n",
    "        try:\n",
    "            cleanup_old_jobs()\n",
    "        except Exception as e:\n",
    "            print(f\"Error in cleanup thread: {str(e)}\")\n",
    "        \n",
    "        # Run cleanup every hour\n",
    "        time.sleep(3600)\n",
    "\n",
    "# Start the cleanup thread when the app starts\n",
    "cleanup_thread = threading.Thread(target=start_cleanup_thread)\n",
    "cleanup_thread.daemon = True\n",
    "cleanup_thread.start()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    from werkzeug.serving import run_simple\n",
    "    run_simple('localhost', 9020, app)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure you set the port 9020 visibility to public!\n",
    "![alt text](images/set-port-visibility.png)\n",
    "\n",
    "If you are in codespace, find the forwarded address for the 9020 port, for example: `https://miniature-adventure-q6w7gwvgqphx9jx-9020.app.github.dev/`, copy and paste the url here:\n",
    "![alt text](images/webapp-set-backend-url.png)\n",
    "\n",
    "If you are hosting locally, you can just use the localhost address instead: `http://localhost:9020`\n",
    "\n",
    "If you get the error \"Address already in use\" use this command: `kill -9 $(lsof -t -i:\"9020\")`\n",
    "\n",
    "If you get auth issues, make sure to `az login --use-device-code` or `azd auth login`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
