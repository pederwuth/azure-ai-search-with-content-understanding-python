{
  "pipeline_id": "bf785c92-81f3-410d-9689-e8d56b441a8b",
  "config": {
    "name": "Document to Summary",
    "description": "Process PDF document with content understanding and generate book summary",
    "tasks": [
      {
        "task_id": "document_processing",
        "inputs": {},
        "settings": {
          "analyzer_template": "analyzer_templates/image_chart_diagram_understanding.json",
          "use_content_books_structure": true,
          "content_type": "book"
        }
      },
      {
        "task_id": "summarization",
        "inputs": {
          "enhanced_markdown": "$enhanced_markdown",
          "book_title": "$book_title",
          "main_folder": "$main_folder"
        },
        "settings": {}
      }
    ],
    "settings": {
      "output_format": "structured",
      "save_intermediates": true
    },
    "metadata": {
      "template_version": "1.0.0",
      "category": "document_processing",
      "estimated_duration_minutes": 25
    }
  },
  "status": "completed",
  "start_time": "2025-09-24T19:14:11.752928",
  "end_time": "2025-09-24T19:14:46.384674",
  "error_message": null,
  "task_executions": {
    "document_processing": {
      "task_id": "document_processing",
      "status": "completed",
      "start_time": "2025-09-24T19:14:11.753663",
      "end_time": "2025-09-24T19:14:25.738098",
      "error_message": null,
      "execution_metadata": {}
    },
    "summarization": {
      "task_id": "summarization",
      "status": "completed",
      "start_time": "2025-09-24T19:14:25.738115",
      "end_time": "2025-09-24T19:14:46.384660",
      "error_message": null,
      "execution_metadata": {}
    }
  },
  "final_outputs": {
    "data": {
      "original_filename": "sample_layout.pdf",
      "custom_filename": "Final Test With Fixed Template",
      "figures_directory": "content/books/tmp01i9vifo-book-20250924_191411-15c467c5/processed/tmp01i9vifo-book-markdown-20250924_191411-15c467c5/tmp01i9vifo-book-figures-20250924_191411-15c467c5",
      "processing_stats": {
        "total_figures": 1,
        "figures_with_content": 1,
        "markdown_characters": 2502,
        "estimated_tokens": 504
      },
      "figures_processed": 1,
      "document_length": 2502,
      "book_title": "Page Objects and Figure Metadata for Automated Document Understanding",
      "main_folder": "content/books/tmp01i9vifo-book-20250924_191411-15c467c5",
      "book_summary": {
        "book_title": "Page Objects and Figure Metadata for Automated Document Understanding",
        "overall_summary": "This book tells a cohesive story about rethinking page content as structured, reusable objects that bridge visual presentation and semantic meaning. It opens by framing the problem: modern documents contain dense, multimodal information where figures, tables, and other page elements convey both human-readable visuals and machine-usable facts. The Page Objects model is introduced as a principled way to represent these elements so that downstream tasks like extraction, indexing, summarization, and accessibility can operate reliably and reproducibly.\n\nEarly chapters develop the theoretical foundations of page objects, defining types, roles, and the metadata conventions that make them interoperable. A central thread is the duality of presentation and metadata: what users see on the page versus the machine-readable annotations that describe it. The book keeps this abstract framework grounded with detailed, concrete examples. One such example is a bar-chart figure that is unpacked into its visible components (bars, axis labels, figcaption) and a structured metadata block containing a title, chart type, topic keywords, descriptive text, a concise summary, and a machine-readable data table.\n\nFrom there the narrative moves to practical engineering and methodological concerns. It explains how to design robust metadata schemas, strategies for annotating legacy documents, and patterns for integrating page objects into document processing pipelines. The emphasis is on reproducible, auditable pipelines that link visual extraction methods with semantic normalization, error handling, and provenance tracking. The text also addresses tooling choices, automation vs manual annotation tradeoffs, and how to combine human expertise with machine learning to scale annotations while maintaining quality.\n\nFinally, the book demonstrates concrete applications and broader implications. Case studies show how consistent figure descriptions enable automated data extraction, improved search and indexing, accessible renderings for assistive technology, and richer user-facing summaries. The closing sections reflect on evaluation, standards alignment, and future directions, including how richer page object representations can support cross-document synthesis, data-driven research, and more inclusive information access.",
        "key_themes": [
          "Page object modeling as a bridge between presentation and semantics",
          "Structured metadata for figures, tables, and other page elements",
          "Practical extraction and annotation workflows",
          "Interoperability and machine-readability",
          "Applications in accessibility, search, and automated summarization"
        ],
        "learning_objectives": [
          "Understand the Page Objects paradigm and why it matters for document understanding",
          "Identify and decompose common page element types, with emphasis on figures and charts",
          "Design and apply machine-readable metadata schemas for visual elements",
          "Implement annotation and extraction pipelines that preserve provenance and quality",
          "Translate structured page object data into downstream applications such as indexing, analytics, and accessible rendering"
        ],
        "chapter_summaries": [
          {
            "chapter_number": 1,
            "chapter_title": "This is title",
            "summary": "This chapter drills into the Page Objects concept by focusing on the Figure element (section 2.2). Building on the earlier, more general discussion of page object structure and element types, it uses a concrete bar-chart example to show how a figure is represented both visually and as embedded metadata. The chapter presents the chart's narrative (figcaption), the raw plotted values for January through June, axis titles, and a machine-readable block that includes a title, chart type, topic keywords, a detailed description, a short human summary, and a markdown-style data table. Together these pieces demonstrate how a single figure encapsulates both presentation (visual labels and numbers) and semantic metadata that supports downstream tasks like automated extraction, indexing, or accessibility enhancements.\n\nThe material emphasizes practical interpretation: identifying the highest and lowest monthly values (April = 450, January = 200), understanding axis labels (Months and Values), and recognizing supporting annotations and footnotes. By juxtaposing the visible figure content with the hidden metadata block, the chapter shows how consistent, structured figure descriptions enable reliable data retrieval and analysis. This builds the reader’s ability to move from recognizing page object types to extracting and using the semantic details they contain, an important step toward automated document understanding and richer user-facing summaries.",
            "key_concepts": [
              "Page Objects",
              "Figure element",
              "Structured metadata",
              "Bar chart interpretation",
              "Axis titles and labels",
              "Machine-readable annotations"
            ],
            "main_topics": [
              "Representation of figures in page objects",
              "Extraction of chart data and summaries",
              "Linking visible content with embedded metadata"
            ],
            "token_count": 518,
            "created_at": "2025-09-24T19:14:34.034955"
          }
        ],
        "total_chapters": 1,
        "created_at": "2025-09-24T19:14:46.383139"
      },
      "overall_summary": "This book tells a cohesive story about rethinking page content as structured, reusable objects that bridge visual presentation and semantic meaning. It opens by framing the problem: modern documents contain dense, multimodal information where figures, tables, and other page elements convey both human-readable visuals and machine-usable facts. The Page Objects model is introduced as a principled way to represent these elements so that downstream tasks like extraction, indexing, summarization, and accessibility can operate reliably and reproducibly.\n\nEarly chapters develop the theoretical foundations of page objects, defining types, roles, and the metadata conventions that make them interoperable. A central thread is the duality of presentation and metadata: what users see on the page versus the machine-readable annotations that describe it. The book keeps this abstract framework grounded with detailed, concrete examples. One such example is a bar-chart figure that is unpacked into its visible components (bars, axis labels, figcaption) and a structured metadata block containing a title, chart type, topic keywords, descriptive text, a concise summary, and a machine-readable data table.\n\nFrom there the narrative moves to practical engineering and methodological concerns. It explains how to design robust metadata schemas, strategies for annotating legacy documents, and patterns for integrating page objects into document processing pipelines. The emphasis is on reproducible, auditable pipelines that link visual extraction methods with semantic normalization, error handling, and provenance tracking. The text also addresses tooling choices, automation vs manual annotation tradeoffs, and how to combine human expertise with machine learning to scale annotations while maintaining quality.\n\nFinally, the book demonstrates concrete applications and broader implications. Case studies show how consistent figure descriptions enable automated data extraction, improved search and indexing, accessible renderings for assistive technology, and richer user-facing summaries. The closing sections reflect on evaluation, standards alignment, and future directions, including how richer page object representations can support cross-document synthesis, data-driven research, and more inclusive information access.",
      "key_themes": [
        "Page object modeling as a bridge between presentation and semantics",
        "Structured metadata for figures, tables, and other page elements",
        "Practical extraction and annotation workflows",
        "Interoperability and machine-readability",
        "Applications in accessibility, search, and automated summarization"
      ],
      "learning_objectives": [
        "Understand the Page Objects paradigm and why it matters for document understanding",
        "Identify and decompose common page element types, with emphasis on figures and charts",
        "Design and apply machine-readable metadata schemas for visual elements",
        "Implement annotation and extraction pipelines that preserve provenance and quality",
        "Translate structured page object data into downstream applications such as indexing, analytics, and accessible rendering"
      ],
      "chapter_summaries": [
        {
          "chapter_number": 1,
          "chapter_title": "This is title",
          "summary": "This chapter drills into the Page Objects concept by focusing on the Figure element (section 2.2). Building on the earlier, more general discussion of page object structure and element types, it uses a concrete bar-chart example to show how a figure is represented both visually and as embedded metadata. The chapter presents the chart's narrative (figcaption), the raw plotted values for January through June, axis titles, and a machine-readable block that includes a title, chart type, topic keywords, a detailed description, a short human summary, and a markdown-style data table. Together these pieces demonstrate how a single figure encapsulates both presentation (visual labels and numbers) and semantic metadata that supports downstream tasks like automated extraction, indexing, or accessibility enhancements.\n\nThe material emphasizes practical interpretation: identifying the highest and lowest monthly values (April = 450, January = 200), understanding axis labels (Months and Values), and recognizing supporting annotations and footnotes. By juxtaposing the visible figure content with the hidden metadata block, the chapter shows how consistent, structured figure descriptions enable reliable data retrieval and analysis. This builds the reader’s ability to move from recognizing page object types to extracting and using the semantic details they contain, an important step toward automated document understanding and richer user-facing summaries.",
          "key_concepts": [
            "Page Objects",
            "Figure element",
            "Structured metadata",
            "Bar chart interpretation",
            "Axis titles and labels",
            "Machine-readable annotations"
          ],
          "main_topics": [
            "Representation of figures in page objects",
            "Extraction of chart data and summaries",
            "Linking visible content with embedded metadata"
          ],
          "token_count": 518,
          "created_at": "2025-09-24T19:14:34.034955"
        }
      ],
      "total_chapters": 1
    },
    "files": {
      "pdf": "/tmp/tmp01i9vifo.pdf",
      "pdf_file": "/tmp/tmp01i9vifo.pdf",
      "enhanced_markdown": "content/pipelines/pipeline_bf785c92-81f3-410d-9689-e8d56b441a8b/task_document_processing/tmp01i9vifo-book-markdown-20250924_191411-15c467c5.md",
      "cache_file": "content/pipelines/pipeline_bf785c92-81f3-410d-9689-e8d56b441a8b/task_document_processing/tmp01i9vifo-book-cache-20250924_191411-15c467c5.json",
      "metadata": "content/pipelines/pipeline_bf785c92-81f3-410d-9689-e8d56b441a8b/task_document_processing/metadata.json",
      "book_summary_file": "content/pipelines/pipeline_bf785c92-81f3-410d-9689-e8d56b441a8b/task_summarization/tmp01i9vifo-book-20250924_191411-15c467c5-summary.json"
    },
    "metadata": {
      "pdf_file": "/tmp/tmp01i9vifo.pdf",
      "enhanced_markdown": "content/books/tmp01i9vifo-book-20250924_191411-15c467c5/processed/tmp01i9vifo-book-markdown-20250924_191411-15c467c5/tmp01i9vifo-book-markdown-20250924_191411-15c467c5.md",
      "cache_file": "content/books/tmp01i9vifo-book-20250924_191411-15c467c5/processed/tmp01i9vifo-book-cache-20250924_191411-15c467c5.json",
      "figures_directory": "content/books/tmp01i9vifo-book-20250924_191411-15c467c5/processed/tmp01i9vifo-book-markdown-20250924_191411-15c467c5/tmp01i9vifo-book-figures-20250924_191411-15c467c5",
      "figures_processed": 1,
      "document_length": 2502,
      "analyzer_id": "enhanced-content-understanding-6e30cfc9-e802-459b-b235-16d5c662fe32",
      "processing_stats": {
        "total_figures": 1,
        "figures_with_content": 1,
        "markdown_characters": 2502,
        "estimated_tokens": 504
      },
      "main_folder": "content/books/tmp01i9vifo-book-20250924_191411-15c467c5",
      "job_id": "15c467c5",
      "timestamp": "20250924_191411",
      "content_type": "book",
      "book_title": "tmp01i9vifo",
      "metadata_file": "content/books/tmp01i9vifo-book-20250924_191411-15c467c5/metadata.json",
      "input_directory": "content/books/tmp01i9vifo-book-20250924_191411-15c467c5/input",
      "processed_directory": "content/books/tmp01i9vifo-book-20250924_191411-15c467c5/processed",
      "markdown_directory": "content/books/tmp01i9vifo-book-20250924_191411-15c467c5/processed/tmp01i9vifo-book-markdown-20250924_191411-15c467c5",
      "folder_structure": "content_books_v1",
      "summarization_completed": true,
      "total_chapters": 1,
      "key_themes_count": 5,
      "learning_objectives_count": 5,
      "created_at": "2025-09-24T19:14:46.383139"
    }
  }
}